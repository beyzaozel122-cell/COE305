{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b864af97",
   "metadata": {},
   "source": [
    "# COE305 – Machine Learning Project (Stage 2 + Stage 3 Combined)\n",
    "## Titanic Survival Prediction using Machine Learning Models\n",
    "\n",
    "**Team Members**\n",
    "- Beyza Özel (210905042)\n",
    "- Derviş Karakoca (220905068)\n",
    "- Tolga Kaplan (220905095)\n",
    "\n",
    "**Dataset (Kaggle)**\n",
    "https://www.kaggle.com/competitions/titanic\n",
    "\n",
    "**GitHub Notebook Link**\n",
    "(Replace with your GitHub link after uploading this notebook)\n",
    "\n",
    "---\n",
    "This notebook contains:\n",
    "- **Stage 2:** Dataset cleaning + Feature Engineering + EDA  \n",
    "- **Stage 3:** Baseline models (**≥ 3 algorithms**) + initial evaluation results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, RocCurveDisplay\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dc00f",
   "metadata": {},
   "source": [
    "## Load Dataset (Kaggle Titanic - train set)\n",
    "\n",
    "We use the Titanic dataset from Kaggle for a binary classification task where:\n",
    "- Target: **Survived** (0/1)\n",
    "- Inputs: passenger demographic & socio-economic features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you downloaded Kaggle 'train.csv', you can use:\n",
    "# raw_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# In our submission, we also keep our Stage files (raw/clean) as Excel:\n",
    "raw_df = pd.read_excel(\"raw (4).xlsx\")\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8774ac",
   "metadata": {},
   "source": [
    "# STAGE 2 — Dataset Cleaning, Feature Engineering, and EDA\n",
    "\n",
    "Stage 2 goal: produce a model-ready dataset by handling missing values, removing noisy columns, and creating useful features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f8966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values overview\n",
    "raw_df.isnull().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Cleaning + Feature Engineering (consistent with our Stage 2 report) ----\n",
    "df = raw_df.copy()\n",
    "\n",
    "# 1) Missing values\n",
    "df[\"Age\"] = df[\"Age\"].fillna(28)          # filled with median age (28)\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")  # filled with mode 'S'\n",
    "df[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n",
    "\n",
    "# 2) Drop Cabin (too many missing values)\n",
    "df = df.drop(columns=[\"Cabin\"], errors=\"ignore\")\n",
    "\n",
    "# 3) Feature Engineering\n",
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "df[\"IsAlone\"] = (df[\"FamilySize\"] == 1).astype(int)\n",
    "\n",
    "# Title extraction from Name\n",
    "df[\"Title\"] = df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n",
    "df[\"Title\"] = df[\"Title\"].replace([\"Mlle\", \"Ms\"], \"Miss\")\n",
    "df[\"Title\"] = df[\"Title\"].replace(\"Mme\", \"Mrs\")\n",
    "rare_titles = [\"Lady\",\"Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"]\n",
    "df[\"Title\"] = df[\"Title\"].replace(rare_titles, \"Rare\")\n",
    "\n",
    "# Fare log transform\n",
    "df[\"Fare_log\"] = np.log1p(df[\"Fare\"])\n",
    "\n",
    "# Build model dataset (drop IDs/text columns not needed for modeling)\n",
    "data = df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"], errors=\"ignore\")\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b5eec",
   "metadata": {},
   "source": [
    "## Stage 2 — EDA (Key Visuals)\n",
    "\n",
    "We include the most important plots that show relationships highlighted in Stage 2:\n",
    "- Target distribution  \n",
    "- Survival rate by Sex and Pclass  \n",
    "- Distributions of Age and Fare_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "data[\"Survived\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Target Distribution (Survived)\")\n",
    "plt.xlabel(\"Survived\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Sex vs Survived\n",
    "pd.crosstab(raw_df[\"Sex\"], raw_df[\"Survived\"], normalize=\"index\").plot(kind=\"bar\")\n",
    "plt.title(\"Survival Rate by Sex\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.show()\n",
    "\n",
    "# Pclass vs Survived\n",
    "pd.crosstab(raw_df[\"Pclass\"], raw_df[\"Survived\"], normalize=\"index\").plot(kind=\"bar\")\n",
    "plt.title(\"Survival Rate by Pclass\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.show()\n",
    "\n",
    "# Age distribution\n",
    "data[\"Age\"].plot(kind=\"hist\", bins=30)\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.show()\n",
    "\n",
    "# Fare_log distribution\n",
    "data[\"Fare_log\"].plot(kind=\"hist\", bins=30)\n",
    "plt.title(\"Fare_log Distribution\")\n",
    "plt.xlabel(\"Fare_log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9971a",
   "metadata": {},
   "source": [
    "# STAGE 3 — Midterm Progress Report (Baseline Models)\n",
    "\n",
    "Stage 3 requirement: **implement ≥ 3 models** and report **baseline results**.\n",
    "We train and evaluate:\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Random Forest\n",
    "\n",
    "Metrics:\n",
    "- Accuracy, Precision, Recall, F1-score, ROC-AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X = data.drop(columns=[\"Survived\"])\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if X[c].dtype != \"object\"]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    # ROC-AUC needs probabilities\n",
    "    proba = pipe.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, preds),\n",
    "        \"Precision\": precision_score(y_test, preds),\n",
    "        \"Recall\": recall_score(y_test, preds),\n",
    "        \"F1\": f1_score(y_test, preds),\n",
    "        \"ROC_AUC\": roc_auc_score(y_test, proba) if proba is not None else np.nan\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"F1\", ascending=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b1813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model detailed report + ROC curve\n",
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "best_pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", best_model)])\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "best_preds = best_pipe.predict(X_test)\n",
    "print(\"Best Model:\", best_model_name)\n",
    "print(classification_report(y_test, best_preds))\n",
    "\n",
    "cm = confusion_matrix(y_test, best_preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# ROC curve (only if predict_proba exists)\n",
    "if hasattr(best_model, \"predict_proba\"):\n",
    "    proba = best_pipe.predict_proba(X_test)[:, 1]\n",
    "    RocCurveDisplay.from_predictions(y_test, proba)\n",
    "    plt.title(f\"ROC Curve - {best_model_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5c70a",
   "metadata": {},
   "source": [
    "## Project Links (Required)\n",
    "\n",
    "- Dataset (Kaggle): https://www.kaggle.com/competitions/titanic  \n",
    "- GitHub Repository: (paste after upload)  \n",
    "- Colab Link (optional): (paste if you use Colab)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

